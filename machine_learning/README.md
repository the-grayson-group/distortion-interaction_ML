# Machine Learning Analysis.

This directory contains the scripts to perform the machine learning analysis after attaining the tuned hyperparameters. There is four directories that correspond to each of the datasets. Inside these is a copy of the hyperparameters and the ```ml_results.pkl``` file which contains the training, testing and validation metrics for each model. This file is generated by [ml_analysis.py.](ml_analyis.py)

## [ml_analysis.py](ml_analyis.py)

### Usage
```python ml_analysis.py 23 path/to/dataset.pkl path/to/hps.pkl```

```for %x in (22 23 14 1 2) do python ml_analysis.py %x path/to/dataset.pkl path/to/hps.pkl ```

This code will loop through every model and only ever perform analysis on one NN at a time. The rationale for this is that TensorFlow can have differing performance when running models sequentially even if caches are cleared. This does mean that multiple submissions are required to cover all targets but, this is a safer way to generate reproducible results.

Once selected, the code will check if a ```ml_results.pkl``` file exists, if it does it will then check if the chosen model is present in the DataFrame. If the model has already been evaluated then it will pass this model. All results are saved to ```ml_results.pkl``` in the current working directory. A ```ml_analysis.log``` file is also generated which contains the printed metrics for the chosen model.

## [ml_visualise.py](ml_visualise.py)

This code takes output from the [ml_analysis.py](ml_analyis.py) and will plot the results and provide the best metric as well as averaged metrics.
### Usage

```python ml_visualise.py -f path/to/ml_results.pkl```

There are two extra tags available:

``` -s ``` if used, will save the outputs to files rather than printing them to the screen.

``` -i ``` if used, will show/save the files individually.

## [ml_rebuild.py](ml_rebuild.py)

This code will rebuild a given model based on arguments given. It is primarily used to quickly evaluate a model's performance and will only show results for one random seed. The reason this code exists is because the [ml_analysis.py](ml_analyis.py) code works by storing all the results for later visualisation with [ml_visualise.py](ml_visualise.py) rather than an rebuilding the model. This also allows for quick testing of a model's performance on an external test set.

### Usage

```python ml_rebuild.py 23 path/to/first/dataset.pkl path/to/second/dataset.pkl path/to/hps.pkl```

The second dataset will be all the test datapoints you want to evaluate.

## [ml_feature_importances.py](ml_feature_importances.py)

This code will perform feature importances analysis via randomly shuffling a feature at testing. This method solely considers one feature at a time relative to the target and therefore, combinations of features and their influence on the target are not considered.

### Usage

```python ml_feature_importances.py 23 path/to/first/dataset.pkl path/to/hps.pkl```

## [test_ranges.py](test_ranges.py)

Small bit of code to generate the test set ranges for each target.



